导航最重要的技术就是
\textbf{SLAM（simultaneous localization and mapping,实时定位和建图技术）}简称SM(不是)。
该技术的基础就是定位。但是可怜的小哨兵并没有GPS。
所以他只能用其他的定位技术，比如激光雷达、IMU、里程计、视觉相机等。
在ROS中，我们使用tf（transform）来表示坐标。frame是坐标系，tf的原理就是通过表示坐标系之间的关系来确定各个坐标系之间的相对位置。
常用的frame有：
\begin{itemize}
\item map：世界坐标系
\item odom：里程计坐标系
\item base\_link：小哨兵的坐标系
\item camera\_link：相机坐标系
\item laser\_link：激光雷达坐标
\item imu\_link：IMU坐标系
\item ...
\end{itemize}

tf的主要信息包含父子节点（及两个坐标系）之间由xyz表示的平移关系和四元数表示的旋转关系。
多个父子节点的tf可以组成一个tf树，树的根节点一般是map，树的叶子节点一般是各个传感器的坐标系。
通过tf树可以算出任意两个节点之间的坐标关系（相对位置）。

\subsection{\quad 激光雷达定位}
先简单介绍一下激光雷达的工作原理：激光雷达的工作原理是通过发射一束激光，然后接收到反射回来的信号，通过解码，得到反射点的坐标，根据反射光的强弱还能获得强度信息。

激光雷达定位主要分为四步：
\begin{enumerate}
\item 所有定位方法开始，都要先要有一张已有的地图，地图上记录了各个障碍物的位置、大小、置信度等信息。将地图上的某一点设为原点，以原点为中心展开的坐标系为map坐标系。
\item 激光雷达扫描四周环境，得到一张激光雷达“视野内”的地图，上面记载了周围的障碍物信息（更多细节将在下一节详细介绍）
\item 将这张地图与已有的地图进行对比匹配，得到雷达最可能存在的位置，将该位置与map坐标系之间的相对位置变化记为map与ladar之间的tf。
\item 结合laser与baselink之间的tf(一般是提前固定写好的，由雷达固定在车体的位置和朝向决定)，得到baselink与map之间的相对位置变化，即得到小哨兵在map坐标系下的位置。
\end{enumerate}
其中匹配方式大体可分为两种：二维和三维匹配。

二维匹配：将三维的点云信息按一定规则压缩到二维（二向箔），获得附近的实时的二维地图，与已有的地图进行匹配（如AMCL算法）。地图为栅格地图（即用像素表示地图，灰度表示障碍物置信度，支持pgm,png,jpg格式，可手动PS修改）。

三维匹配：直接将扫描到的点云与之前存储的点云匹配，定位更准确，但是匹配速度慢(如ICP,NDT匹配算法)。常会用到kd-tree,oct-tree等数据结构加速匹配。一般与先前一小段时间内的储存的点云进行匹配，获得相对移动，是一种动态的匹配。
因此需要将较久之前扫描到的点云，或者距离较远的点云从kdtree之类的数据结构中清理掉，防止匹配目标过大。（point-lio里的$fov\_segment()$函数就是干这个的所以不能删掉@wzx）

运动过程中多用动态的匹配，以便较快的更新定位，提高实时性。与整张全局地图的匹配，一般在特定情况下（如刚开机上电不知道自己在哪的时候；定位可能出现偏差的情况；或者执行完恢复行为之后。也可以时不时重定位一下，上赛季就是这么干的，效果好像不太行QAQ）才进行，又叫重定位，即直接清零更新baselink和map之间的tf。
\subsection{\quad 里程计，IMU定位}
里程计定位较为简单，直接获取机器人各个方向运动的里程，加在map坐标系下的位置即为小哨兵的位置。
IMU，即惯性测量单元，可以测量各方向的角速度和线加速度，通过积分，获得类似里程计的数据，加在map坐标系下的位置即为小哨兵的位置。

\subsection{视觉定位}
视觉定位也是近年来较为流行的SLAM技术，它与激光雷达定位类似，但他获取的特征信息在相同情况下比激光雷达多。
它通过提取图像中的特征点（一般是角点），与原先存储的地图里的特征点对比匹配，计算出相机的相对位移，累加后得到小哨兵在map坐标系的坐标变换。

\subsection{多传感器融合}
以上各个定位方法都有自己的局限性：
\begin{itemize}
\item imu,里程计定位：由于IMU和里程计对运动（速度，加速度）测量的精度较高，定位较为准确。但由于其本身稳定性较差，易受干扰（如IMU受热噪声干扰的零漂，轮式里程计打滑等情况）；
        且他们都是“开环”的测量方式，一旦出现意外情况（比如受干扰，或者某些情况下超过其测量范围(比如被别的机器人肘了一下，瞬时加速度太大IMU测量不了)），
        测量的位置歪掉了，就再也回不来了，因为没法校正。
\item 视觉定位：视觉定位的精度较低，且受相机的分辨率、光照、遮挡等因素影响较大。且对需要物体纹理较多效果才比较好。
\item 雷达定位：激光雷达只能获取深度信息，这会导致在一些特殊情况中定位失效。
        如雷达在非常长的两堵一模一样的墙之间前进，虽然车在前进，但在雷达的视野里，左右离墙的距离不变，而前后因为超出探测距离所以数据也不变，他就以为自己没有运动了；
        又如雷达在一个一个正方形房间的正中心，你趁雷达不注意（即在两次雷达扫描的间隔之间），把他旋转90度。在雷达的视野里，前后左右的障碍物与之前的完全相同，所以他会以为自己没旋转。
\end{itemize}
为了解决这些问题，人们将多种传感器的数据融合在一起得到更准确定位方法。

最常见的融合方法（也是我们现在使用的方法）是激光雷达和里程计的融合。
我们新建一个节点Odom，他作为map的子节点，作为base\_link的父节点。
雷达输出odom到baselink的tf，而map到odom的tf作为校正数值记录，如里程计与雷达数据的偏差等。
这样，小哨兵的位置就通过激光雷达和里程计 fusion 的方式得到。

其他的融合方法还有：激光雷达与视觉融合，将点云与图像匹配，使点云除了位置信息外，还能拥有颜色等信息。
